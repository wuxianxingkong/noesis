<?xml version="1.0"  encoding="ISO-8859-1" ?> 
<!DOCTYPE sys-ents [ <!ENTITY bibliography SYSTEM "bibliography.xml"> ]> 
<?xml-stylesheet type="text/xsl" href="../book.xsl"?>


<document>
&bibliography;
<title>Graph Theory: The Mathematics of Networks</title>

<text>
Graph Theory is the mathematical study of graphs (or networks).
</text>

<text>
[idea] A graph as a mathematical representation of a system composed of interconnected elements. Applications: human interactions, transportation systems, communication networks, electronic circuits... They can be used to represent any kind of relationship.
</text>

<document>
<tag>graph-theory-fundamentals</tag>
<title>Graphs and their terminology</title>


<text>
From a formal point of view, a <term>graph</term> <eqn>G=(V,E)</eqn> is a finite non-empty set <eqn>V</eqn> of vertices together with a possibly empty set <eqn>E</eqn> of 2-element subsets of <eqn>V</eqn> called edges. A graph <eqn>G=(V,E)</eqn>, therefore, has a <term>vertex set</term> <eqn>V</eqn> and an <term>edge set</term> <eqn>E</eqn>, which are often denoted by <eqn>V(G)</eqn> and <eqn>E(G)</eqn>, respectively. Vertices are often referred to as points or, more commonly, nodes. Edges are sometimes called lines or links. When talking about networks, we will prefer the terms nodes and links.
</text>

<text>
Nodes (vertices) correspond to the elements of the system represented by the graph, whereas links (edges) represent their connections. In a social network, for instance, people are represented as nodes while friendship relationships are represented by links between pairs of nodes. In practice, we will restrict ourselves to dyadic (pairwise) relationships when representing graphs.
</text>

<text>
Any member <eqn>e={u,v}</eqn> of <eqn>E(G)</eqn> is an <term>edge</term> in <eqn>G</eqn> with end vertices <eqn>u</eqn> and <eqn>v</eqn>. Both <eqn>u</eqn> and <eqn>v</eqn> are incident with the edge <eqn>e</eqn>. An edge <eqn>e={u,v}</eqn> is said to join <eqn>u</eqn> and <eqn>v</eqn> and can be denoted by <eqn>uv</eqn> or <eqn>vu</eqn>.
</text>

<text>
A self-loop, or <term>loop</term> for short, is an edge <eqn>vv</eqn> from one vertex <eqn>v</eqn> to itself.
</text>


<text>
When <eqn>{u,v}</eqn> is an edge in <eqn>G</eqn>, <eqn>u</eqn> and <eqn>v</eqn> are adjacent vertices and they are said to be neighbors of each other. Likewise, when both <eqn>{u,v}</eqn> and <eqn>{v,w}</eqn> are edges in <eqn>G</eqn>, they are said to be adjacent edges.
</text>

<text>
The number of vertices in the graph is the <term>order</term> of the graph, whereas the number of edges in the graph is the <term>size</term> of the graph. We will typically use <eqn>n</eqn> to denote the order of the graph (i.e. its number of nodes) and <eqn>m</eqn> to denote its size (i.e. its number of links).
</text>

<text>
++ Drawing a graph as a diagram: Each point (or small circle) represents a node and two points are joined by a line if the corresponding nodes are joined by an edge in the graph.
</text>

<!--
{V \choose 2} the set of all pairs of its vertices. 
The graph \overline{G} = (V, {V \choose 2} \ E) is the <term>complementary graph</term>. 
Two vertices of V are adjacent in G if and only if they are not adjacent in \overline{G}

The <term>line graph</term> L(G) of a graph G has as vertices the edges of G; two edges
of G are adjacent in L(G) if and only if they have a common vertex in G. For
example, the line graph of the complete graph Kn is the triangular graph Tn
-->


<!-- Multigraphs -->

<document>
<tag>graph-theory-multi</tag>
<title>Multigraphs</title>

<text>
In multigraphs, there are pairs of vertices that are connected by more than one edge. An edge is said to be a multiedge when it appears more than once in the same graph (i.e. multigraph). 
</text>

<text>
In multigraphs, we replace the edge set of an ordinary graph by a family <eqn>E</eqn> of two-element subsets of <eqn>V</eqn>. 
Formally, we define a <term>multigraph</term> as a triple <eqn>(V, E, J)</eqn> where <eqn>J</eqn> is a mapping from <eqn>E</eqn> to the set of two-element subsets of <eqn>V</eqn>, so that we can distinguish different edges connecting the same pair of vertices. <eqn>J</eqn> is called the incidence map because the image <eqn>J(e)</eqn> of an edge <eqn>e</eqn> is the set <eqn>{u, v}</eqn> of the end vertices of <eqn>e</eqn>.
</text>

<text>
When <eqn>J(e) = J(e')</eqn>, we say that edges <eqn>e</eqn> and <eqn>e'</eqn> are <term>parallel edges</term>.
</text>

<text>
Multigraphs can be generalized if we allow loops, i.e. edges <eqn>e</eqn> whose <eqn>J(e)</eqn> is a singleton set <eqn>{v}</eqn>. A structure that allows both parallel edges and loops is often called <term>pseudographs</term>.
</text>

<text>
A graph without multiedges nor self-loops is called a <term>simple graph</term>. Multiedges and self-loops introduce some subtetlies in the design of graph algorithms, hence simple graphs are often preferred.
</text>

</document>


<!-- Undirected / directed -->

<document>
<tag>graph-theory-directed</tag>
<title>Directed graphs (a.k.a. digraphs)</title>

<text>
From a formal point of view, a directed graph <eqn>G=(V,E)</eqn> is a finite non-empty set <eqn>V</eqn> of vertices (or nodes) together with a possibly empty set <eqn>E</eqn> of ordered pairs of vertices called directed edges (also known as arcs). In other words, <eqn>V \neq \emptyset</eqn> and <eqn>E \subseteq V \times V</eqn>. Henceforth, we will stick to this definition both for directed and undirected graphs.
</text>

<text>
In scenarios such as the social network mentioned at the beginning of this section, where we consider friendship relationships to be symmetric, links will be undirected. In undirected graphs, therefore, edges are two-element subsets of <eqn>V(G)</eqn>. An edge <eqn>{u,v}</eqn> can then be denoted as <eqn>uv</eqn> or <eqn>vu</eqn>, since both are considered to be equivalent. In other words, both <eqn>(u,v)</eqn> and <eqn>(v,u)</eqn> belong to <eqn>E(G)</eqn> as defined above.
</text>


<text>
++ Directed graphs (= digraphs): undirected graphs for nondirectional links, directed graphs for directional links.

Examples (many applications concerning traffic and transportation networks): road networks (lanes in both directions) are undirected vs. street networks within cities (typically directed due to one-way streets; program flow graphs are typically directed (dependences)...
</text>

<text>
J: Formally, a directed graph or, for short, a digraph is a pair G = (V,E) consisting of a finite set V and a set
E of ordered pairs (a, b), where a \neq b are elements of V. The term arc is usually employed instead
of edge to distinguish between the directed and the undirected case. 

Instead of e = (a, b), we again write e = ab; a is called the start vertex or tail, and b the end vertex or head of e; i.e. <eqn>tail \rightarrow head</eqn>. We say that a and b are incident with e, and call two edges of the form ab and ba antiparallel. 

(u,v): u is said to be adjacent to v and v is said to be adjacent from u.
</text>

<text>
++ Drawing: To draw a directed graph, we proceed as in the undirected case, but indicate the direction of a directed edge by an arrowhead.
</text>

<text>
J: "Replacing each directed edge of the form (a, b) by an undirected edge {a, b}, we obtain the underlying multigraph |G|. Replacing parallel
edges in |G| by a single edge, we get the underlying graph (G). Conversely, let G = (V,E) be a multigraph. Any directed multigraph H with |H| = G is
called an orientation of G. Replacing each edge ab in E by two arcs (a, b) and (b, a), we get the associated directed multigraph
\overrightarrow{G}; we also call \overrightarrow{G} G the complete orientation of G. "
</text>

<text>
We say that a digraph G is symmetric if,whenever (u,v) is an arc of G, then (v,u) is also an arc of G. We say that a digraph is oriented if, whenever (u,v) is an arc of G, then (v,u) is not an arc of G.
</text>

</document>


<!-- Weighted graphs -->

<document>
<tag>graph-theory-weighted</tag>
<title>Weighted graphs</title>

<text>
++ Binary vs. weighted graphs: binary graphs for dichotomous links (ties are either present or absent for each pair of nodes), weighted graphs for valued links (that indicate the strength, intensity, or frequency of the tie between each pair of actors). Binary graphs, also known as unweighted graphs...

- Each edge is assigned a numerical value or weigth; e.g. road network (length, traversal time, construction cost, speed limit...)
</text>

</document>



<!-- Labeled graphs -->

<document>
<tag>graph-theory-label</tag>
<title>Labeled graphs and attribute graphs</title>

<text>
++ Labeled graphs: Each vertex is assigned a name or identifier (may not be unique). Note: the index of a node within the graph is often employed as a surrogate for the node identifier (for convenience when implementing efficient algorithms and also for preserving anonymity in some applications).
</text>

<text>
++ Attribute graphs @ attributes at nodes and edges
</text>

</document>

<!-- Dynamic graphs -->

<document>
<tag>graph-theory-dynamic</tag>
<title>Dynamic graphs</title>

<text>
In a static graph, the properties of nodes, links, and mapping function
remain unchanged over time. For example, the number of nodes and links remains
constant, and the mapping function does not change. In a dynamic graph, the number
of nodes and links, the shape of the mapping function, and perhaps other properties of
the graph change over time. For example, the values assigned to nodes and links, as
well as the number of nodes and links, may vary.
</text>

<text>
L: A graph is a 3-tuple: G = (N,L,f), where N is a set of nodes, L is a set of links, and f is a mapping function (table) that maps links onto node pairs. Nodes directly connected by a link are called adjacent nodes. A static graph
retains its initial structure, forever. A dynamic graph changes its nodes,
links, and/or mapping function over time.
</text>

</document>

<!-- Networks -->


<document>
<tag>graph-theory-network</tag>
<title>Networks</title>

<text>
L: The structure portion of a network is easily modeled by graph theory.

L: Specifically, the network itself can be defined in terms of a set, G = {N, L, f}, where N is a set of nodes, L a set of links, and f : N - N a mapping function that defines the structure of G—how nodes are connected to each other through links. The mapping function contains enough information to draw the graph on a planar piece of paper using dots as nodes and lines as links.
</text>

<text>
Graph theory, however, is inadequate to define the second key ingredient of a network: its dynamic behavior.

L: The dynamic portion of a network is defined by a set of microrules governing the behavior of nodes and links. These rules are given at the microlevel, to distinguish them from macrolevel behaviors of networks. Specifically, microlevel rules dictate the behavior of links and nodes, and macrolevel rules dictate the emergence of global properties of a network. For example, preferential attachment—links are attracted to nodes with a lot of links, already—is a microrule, whereas the power law describing the degree sequence distribution of a network is a macrolevel rule. As network scientists, we are concerned mainly with understanding macrolevel properties by studying microrules—and sometimes the reverse.

L: A complete definition of network G must include both structural and behavioral information. For example, G(t) = { N(t), L(t), f(t) } is a set-theoretic definition of network G with a dynamic dimension 


L: G(t) is a function of time t and the number, values, and mappings of nodes and links as they change with time. The
actual behaviors of G(t) are expressed algorithmically, typically in the form of a computer algorithm. 

L: Definition of Network as a 3-tupleG(t) = ( N(t), L(t), f(t), J(t) ) where, 
t - time, simulated or real
N - nodes, also known as vertices or “actors”
L - links, also known as edges
f : N - N - topology: mapping function that connects nodepairs, yielding topology
J - algorithm for describing behaviors of nodes and links versus time (microrules)

N, L, and f and time-varying in dynamic networks.

MT: A macro-level model explains how the world works with an equation. Micro-level models are called agent-based models.
1. Agents: The objects of our model, i.e. a set of autonomous agents (who might decide to collaborate)
2. Behavior: Agent behavior: rules they follow (might be pretty simple).
3. Outcome: When agents follow their rules, it creates something at the macro level, sometimes surprising [emergence]
</text>

</document>

</document>


<!-- Node degree -->

<document>
<tag>graph-theory-degree</tag>
<title>Node degree and degree sequences</title>

<text>
The set of neighbors of a vertex <eqn>v</eqn> is the neighborhood of <eqn>v</eqn> and is denoted by <eqn>N_G(v)</eqn>. Technically, this is the open neighborhood of the vertex (the closed neighborhood would also include the vertex <eqn>v</eqn> itself). 
</text>

<text>
The degree of a vertex <eqn>v</eqn> in a graph <eqn>G</eqn> is the number of vertices in <eqn>G</eqn> that are adjacent to <eqn>v</eqn>, i.e. the size of its neighborhood: <eqn>deg_G(v) = |N_G(v)|</eqn>.
</text>

<text>
Since every edge is counted twice (once for each one of its incident vertices), the sum of all vertex degrees is twice the size of the graph, i.e. <eqn>\sum deg_G(v) = 2|E(G)| = 2m</eqn>, a basic result known as the First Theorem of Graph Theory and also referred to as the Handshaking Lemma <cite>Chartrand et al. 2011</cite>. Since the sum of all vertex degrees is even, the number of vertices of odd degree must also be even. Moreover, the average degree of a graph <eqn>G</eqn> of order <eqn>n</eqn> and size <eqn>m</eqn> can be easily computed, since it is always <eqn>2m/n</eqn>.
</text>

<text>
The minimum degree among the vertices of G is denoted by <eqn>\delta(G)</eqn>, while the maximum degree in G is denoted by <eqn>\Delta(G)</eqn>. Hence, <eqn>0 \le \delta(G) \le deg_G(v) \le \Delta(G) \le n-1</eqn> for simple graphs.
</text>

<text>
When the nodes with the largest degrees in a given network are much more connected that other nodes in the network, they are typically called hubs.
</text>


<document>
<tag>graph-theory-degree-sequence</tag>
<title>Degree sequences</title>

<text>
An integer partition p = (p_1, ..., p_n) where p_i is the degree of the ith highest-degree node in the graph.

p is an integer partition of 2m, i.e. sum p_i = 2m, in undirected graphs, since each edge contributes to the degree of two nodes.

Not all integer partitions correspond to actual graphs.

An algorithm to build a graph given a degree sequence: the highest-degree node is connected to the following node; the degree sequence is updated by decrementing p_1 and p_2 (and reorder the partition), resulting in a smaller partition; the process is repeated until the degree sequence is full of zeroes (or a negative value appears, which means the graph was not realizable).

The algorithm above is deterministic. If we want a random graphs with the given degree sequence, we can generate them by flipping edges: from (x,y) and (w,z) we create (x,w) and (y,z), which yields a different graph with the same degree sequence (albeit it should be noted that the resulting graph is not necessarily connected).
</text>


<text>
The degree sequence distribution of a network, for example, is a histogram of percentage of nodes with degree d versus d.
Different kinds of networks exhibit different degree sequence distributions:
e.g. 
- A random network has a degree sequence distribution that obeys a binomial distribution, 
- and a scale-free network’s degree sequence obeys a power law.
</text>
</document>


<document>
<tag>graph-theory-degree-directed</tag>
<title>Directed graphs: In-degree and out-degree</title>

<text>
In a directed graph, links are directed and we distinguish between

- The out-neighborhood <eqn>N^+(v)</eqn> of a vertex <eqn>v</eqn> (the set of vertices adjacent to v)

- The in-neighborhood <eqn>N^-(v)</eqn> of a vertex <eqn>v</eqn> (the set of vertices adjacent from v)
</text>

<text>
The out-degree <eqn>deg_{out}(v)</eqn> of a vertex v is the number of edges with tail v, i.e. <eqn>deg_{out}(v) = | N^+(v) |</eqn>

The in-degree <eqn>deg_{in}(v)</eqn> of a vertex v is the number of edges with head v, i.e. <eqn>deg_{in}(v) = | N^-(v) |</eqn>

The full degree of a vertex is defined by <eqn>deg(v) = deg_{out}(v) + deg_{in}(v)</eqn>
</text>

<text>
The First Theorem of Digraph Theory can be stated as
</text>

<equation>
\sum deg_{out}(v) = \sum deg_{in}(v) = |E(G)| = m
</equation>

</document>


<document>
<tag>graph-theory-degree-weighted</tag>
<title>Weighted graphs: Node strength</title>

<text>
++ Weighted graphs: Node strength instead of node degree = Sum of all the edge weights of a node.
</text>

</document>

</document>



<!-- Subgraphs -->

<document>
<tag>graph-theory-subgraphs</tag>
<title>Subgraphs</title>


<text>
Let <eqn>G=(V,E)</eqn> be a graph and <eqn>V'</eqn> be a subset of <eqn>V</eqn>. Using the notation in <cite>Jungnickel 2007</cite>, by <eqn>E|V'</eqn> we denote the set of all edges <eqn>e \in E(G)</eqn> that have both vertices in <eqn>V'</eqn>. The resulting graph <eqn>G'=(V',E|V')</eqn> is the induced subgraph of <eqn>G</eqn> on <eqn>V'</eqn> and it will be denoted as <eqn>G|V'</eqn>.
</text>

<!--
For a subset T of the vertex set V of a graph G we denote by G\ T the induced subgraph on V \ T. This graph arises from G by omitting all vertices in T and all edges incident with these vertices. For a one-element set T = {v} we write G \ v instead of G \ {v}. 
--> 

<text>
Each graph of the form <eqn>G'=(V',E')</eqn> where <eqn>V' \subset V</eqn> and <eqn>E' \subseteq E|V'</eqn> is said to be a subgraph of <eqn>G</eqn>.
</text>

<text>
A subgraph of the same order of the original graph, i.e. when <eqn>V'=V</eqn>, is a spanning subgraph. 
</text>

<text>
A k-factor is a k-regular spanning subgraph. When the edge set of a graph is divided into k-factors, such a decomposition is called a k-factorization of the graph. A 1-factorization, or factorization for short, can exist only if <eqn>G</eqn> has an even number of vertices and it is also called a resolution. Factorizations of <eqn>K_{2n}</eqn> can be interpreted as schedules for tournaments of <eqn>2n</eqn> teams and always exist <cite>Jungnickel 2007</cite>.
</text>


<!-- Isomorphism -->

<note>
<tag>graph-theory-isomorphism</tag>
<title>Graph isomorphism</title>

<text>
When are two graphs considered different? Basically, when they do not have the same structure, which leads as to the concept of graph isomorphism.
</text>

<text>
Two graphs <eqn>G = (V(G),E(G))</eqn> and <eqn>H = (V(H),E(H))</eqn> are called isomorphic if there is a bijective function <eqn>\phi: V(G) \rightarrow V(H)</eqn> such that <eqn>(u, v) \in E(G)</eqn> if and only if <eqn>(\phi(u), \phi(v)) \in E(H)</eqn> for all <eqn>u, v \in V(G)</eqn>.
</text>

<text>
The isomorphisms of a graph G to itself are called automorphisms.
</text>

<text>
When two graphs G and H are isomorphic, they have the same number of nodes (i.e. the same order), the same number of links (i.e. the same size), and the degrees of the vertices of G are the same as the degrees of the vertices of H.
</text>
</note>

</document>

<!-- Graph connectivity -->

<document>
<tag>graph-theory-connectivity</tag>
<title>Graph connectivity</title>


<text>
Graphs are sparse when existing edges represent a small fraction of the possible vertex pairs. They are dense when there are edges between most vertex pairs. Dense graphs typically have a quadratic number of edges, whereas sparse graphs are linear in size. The application domain often imposes limits of the number of edges that are incident on any given node within the graph, hence most real-world graphs are actually sparse.
</text>


<document>
<tag>graph-theory-paths</tag>
<title>Paths and cycles</title>

<!-- Walks, trails, and paths -->

<text>
A walk is a sequence of adjacent edges in a graph. Formally, a sequence of edges <eqn>(e_1, ..., e_n)</eqn> is a walk is there are vertices <eqn>v_0, ..., v_n</eqn> such that <eqn>e_i = v_{i-1}v{i}</eqn> for <eqn>i = 1..n</eqn>. For the sake of simplicity, we can specify a walk by its sequence of vertices <eqn>(v0, ..., vn)</eqn>, provided that <eqn>v_{i-1}v_i</eqn> is an edge in the graph for <eqn>i = 1..n</eqn>. Given a walk <eqn>(v0, ..., vn)</eqn>, <eqn>v_0</eqn> is said to be its start vertex, <eqn>v_n</eqn> is its end vertex, and <eqn>n</eqn> is its length. When the start vertex and the end vertex are the same, i.e. <eqn>v_0 = v_n</eqn>, the walk is said to be a closed walk. 
</text>

<text>
When all the edges in a walk are distinct, the walk is called a trail. Consequently, a closed walk without repeating edges is a closed trail.
</text>

<text>
When, both edges and nodes are distinct, the trail becomes a path. It should be noted that any walk always contains a path from its start vertex to its end vertex (plus some optional detours). 
</text>

<!-- @ directed graphs -->

<text>
- A sequence of edges (e1, . . . , en) is called a trail if the corresponding sequence of edges in the underlying graph |G| is a trail.
- If (v0, . . . , vn) is the corresponding sequence of vertices, vi-1vi or vivi-1 must be an edge of G. In the first case,
we have a forward edge, in the second a backward edge.
- If a trail consists of forward edges only, it is called a directed trail;
- any directed walk W with start vertex a and end vertex b, where a \neq b, contains a directed path from a to b.
</text>

<!-- as subgraphs --> 

<text>
Paths and cycles are important kinds of subgraphs:

- A path <eqn>P_n</eqn> is a graph of order n and size n-1 whose vertices can be labeled <eqn>v_1, v_2, ..., v_n</eqn> and whose edges are <eqn>v_iv_{i+1}</eqn> for <eqn>i=1,2,...,n-1</eqn>. 

- A cycle <eqn>C_n</eqn> is a graph of order n and size n whose whose vertices can be labeled <eqn>v_1, v_2, ..., v_n</eqn> and whose edges are <eqn>v_1v_n</eqn> and <eqn>v_iv_{i+1}</eqn> for <eqn>i=1,2,...,n-1</eqn>. The cycle <eqn>C_3</eqn> is called a triangle or triad.
</text>

<!-- Cycles -->

<text>
A cycle (or circuit) is a closed trail with <eqn>n \geq 3</eqn> and distinct nodes (except, of course, <eqn>v_0 = v_n</eqn>). 
</text>

<text>
Any closed walk of
odd length necessarily contains a cycle, whereas some closed walks of even length do not contain cycles (e.g. jumping from the starting node to one of its neighbors and returning back to it). 

+ any directed closed walk contains a directed cycle.
</text>

<text>
A cycle of length three is called a triangle.  ++transitive relationships
</text>

<text>
Acyclic graphs do not contain any cycles. ++ important classes: DAGs, trees
</text>


 
 

<document>
<tag>graph-theory-eulerian</tag>
<title>Eulerian circuits</title>

<text>
The Königsberg bridge problem studied by Euler in 1736, which originated the study of graph theory, asked for a circular tour containing every edge in the graph (a multigraph in the Königsberg brige problem, actually, since it contained two pairs of parallel edges). Such circular tours, which traverse every edge in the graph, are called Eulerian circuits.
</text>

<text>
Formally, an Eulerian trail of <eqn>G</eqn> is a trail that contains every edge in <eqn>G</eqn> exactly once. When the trail is closed, it is an Euler tour. A graph is Eulerian when it contains an Euler tour. The terms Eulerian cycle and Eulerian circuit are often used instead of Euler tour, even though an Euler tour can include the same vertices more than once. Likewise, the term Eulerian path is usually employed to refer to Eulerian trails.
</text>

<text>
Euler's theorem characterizes Eulerian graphs <cite>Euler 1736</cite>. Given a connected graph <eqn>G</eqn>, Euler's theorem establishes that the following statements are equivalent:
</text>

<list>
<item>G is Eulerian.</item>
<item>Each vertex in G has even degree.</item>
<item>The edge set of G can be partitioned into cycles.</item>
</list>

<text>
Since Euler tours must traverse all the edges in a graph and each occurrence of a vertex in the Euler tour adds two to its degree, it follows that all vertices must have an even degree. This result proves that the Königsberg bridge problem has no solution, since all the vertices in its associated graph have odd degrees.
</text>

<text>
For directed graphs, an analogue theorem can be obtained. For connected directed graphs, the following statements are equivalent:
</text>

<list>
<item>G has a directed Euler tour.</item>
<item>G is pseudosymmetric, i.e. <eqn>deg_{in}(v)=deg_{out}(v)</eqn> for every vertex.</item>
<item>The edge set of G can be partitioned into directed cycles.</item>
</list>

<text>
I can also be proved that, given a connected graph with exactly <eqn>2k</eqn> vertices of odd degree, with <eqn>k \neq 0</eqn>, the edge set of the graph can be partitioned into <eqn>k</eqn> trails. Taking this into account, it is easy to obtain the following results:
</text>

<list>

<item>
An undirected graph contains an Eulerian circuit iff (1) it is connected, and (2) each vertex is of even degree.
</item>

<item>
An undirected graph contains an Eulerian path iff (1) it is connected, and (2) all but two vertices are of even degree. These two vertices will be the start and end points of any Eulerian path.
</item>

</list>

<text>
Similar results can be derived for directed graphs:
</text>

<list>

<item>
A directed graph contains an Eulerian cycle iff (1) it is strongly-connected, and (2) each vertex has the same in-degree as out-degree.
</item>

<item>
A directed graph contains an Eulerian path from x to y iff (1) it is connected, and (2) all other vertices have the same in-degree as out-degree,
with x and y being vertices with in-degree one less and one more than their out-degrees, respectively.
</item>

</list>

<!-- The line graph of an Eulerian graph is likewise Eulerian, butt the converse is false in general. -->

</document>


<document>
<tag>graph-theory-hamiltonian</tag>
<title>Hamiltonian circuits</title>

<text>
Hamiltonian circuits are somehow related to Euler tours. Whereas every edge is traversed by an Euler tour, Hamiltonian cycles require visiting each node in the graph exactly once.
</text>

<text>
Formally, a Hamiltonian path or traceable path is a path that visits every vertex exactly once. A graph that contains a Hamiltonian path is called a traceable graph. A graph is said to be Hamiltonian-connected if, for every pair of vertices, there is a Hamiltonian path between them. A Hamiltonian cycle, Hamiltonian circuit, vertex tour, or graph cycle is a circuit that visits each vertex exactly once (except the vertex that is both the start and end, which is visited twice). Finally, a graph that contains a Hamiltonian cycle is called a Hamiltonian graph.
</text>

<!-- Any Hamiltonian cycle can be converted to a Hamiltonian path by removing one of its edges, 
but a Hamiltonian path can be extended to Hamiltonian cycle only if its endpoints are adjacent. -->


<text>
Although Euler tours and Hamiltonian circuit look similar, they are quite different problems. While it is easy to find an Euler tour, it is hard to find a Hamiltonian circuit. In fact, there is no nice characterization of Hamiltonian graphs.
</text>

<text>
We know, for instance, that some kinds of graphs are Hamiltonian, including complete graphs <eqn>K_n</eqn> with more than two vertices, every cycle graph, every tournament, and every platonic solid. We also know some sufficient conditions for the existence of a Hamiltonian cycle, usually in the form of statements about the degrees of the vertices in the graph:
</text>

<list>

<item>Dirac's theorem (1952): A graph with more than two vertices is Hamiltonian if every vertex in the graph has degree <eqn>\geq n/2</eqn>.</item>

<item>Ore's theorem (1960): A graph with more than two vertices is Hamiltonian if, for every pair of non-adjacent vertices, the sum of their degrees is n or greater.</item>

<item>Bondy–Chvátal theorem (1972): A graph <eqn>G</eqn> is Hamiltonian if and only if its closure <eqn>[G]</eqn> is Hamiltonian.</item>

</list>

<text>
Given a graph <eqn>G</eqn> defined on <eqn>n</eqn> vertices, its closure <eqn>[G]</eqn> is constructed by successively adding edges <eqn>uv</eqn> to <eqn>G</eqn> for all nonadjacent pairs of vertices <eqn>u</eqn> and <eqn>v</eqn> that satisfy the following condition: <eqn>deg_G(v) + deg_G(u) \geq n</eqn>. In the closure of <eqn>G</eqn>, therefore, for any two non-adjacent vertices <eqn>u</eqn> and <eqn>v</eqn>, we always have <eqn>deg_G(u) + deg_G(v) &lt; n</eqn>.
</text>

<text>
Since complete graphs are Hamiltonian, all graphs whose closure is complete will also be Hamiltonian. This result subsumes Dirac's and Ore's theorems, hence showing that the Bondy-Chvátal theorem theorem generalizes the previous two ones.
</text>

<text>
Similar characterizations can be obtained for directed graphs:
</text>

<list>

<item>
Ghouila-Houiri theorem (1960): A strongly connected simple directed graph <eqn>D</eqn> with <eqn>n</eqn> vertices is Hamiltonian if <eqn>deg_{in}(v) \geq n/2</eqn> and <eqn>deg_{out}(v) \geq n/2</eqn> for all vertices in <eqn>D</eqn>.
</item>

<item>
Meyniel's theorem (1973): A strongly connected simple directed graph with n vertices is Hamiltonian if the sum of the full degrees of two distinct non-adjacent vertices is at least <eqn>2n-1</eqn>, i.e. <eqn>deg(x) + deg(y) \geq 2n-1</eqn> for all pairs of non-adjacent vertices <eqn>x</eqn> and <eqn>y</eqn>.
</item>

</list>

<text>
The number of vertices in these sufficient conditions is doubled with respect to the undirected case because each undirected edge corresponds to two directed arcs and the full degree of a vertex in the directed graph is twice its degree in the undirected graph.
</text>

<!-- The line graph of an Eulerian graph is Hamiltonian: If G is Eulerian, then L(G) is Hamiltonian -->
<!-- The line graph of a Hamiltonian graph is Hamiltonian. -->
<!-- A tournament (with more than 2 vertices) is Hamiltonian if and only if it is strongly connected. -->


<text>
It should be noted that the number of different Hamiltonian cycles in a complete undirected graph on <eqn>n</eqn> vertices is <eqn>(n-1)!/2</eqn>, <eqn>(n-1)!</eqn> in a complete directed graph. Many important problems can be stated as finding the optimal Hamiltonian cycle in some sense and, since no general efficient method is known for finding one, their resolution requires the use of combinatorial optimization techniques. The traveling salesman problem (TSP) is probably the most famous of such problems: planning the minimum cost route for a traveling salesman who must visit <eqn>n</eqn> cities, where cost is typically associated to the traveled distance, even though other optimization criteria could be used (e.g. the time it takes to complete the tour or its actual monetary cost, which might depend on many other factors beyond time and distance). From a formal point of view, the solution to the TSP involves finding the cyclic permutation <eqn>\pi</eqn> of the graph vertex set that minimizes the cost function. Just enumerating the potential solutions is prohibitive in practice, since there are <eqn>(n-1)!</eqn> of them. Actually, there are <eqn>n!</eqn> permutations, but we can always set the starting node of the circuit, hence the <eqn>n</eqn> factor we can save.
</text>


</document>

</document>


<document>
<tag>graph-theory-components</tag>
<title>Connected components</title>

<text>
++ Connected graphs, weakly-connected vs. strongly-connected components (a.k.a. blocks)

A graph G is strongly connected if all nodes in G can reach v and are reachable from v.

J: Finally, a directed multigraph G is called connected if the underlying graph |G| is connected.


J: We say that a vertex b of a digraph G is accessible from a vertex a if there is a directed walk with start vertex a and end vertex b. As before, we allow walks to have length 0 so that each vertex is accessible from itself. 

A digraph G is called strongly connected if each vertex is accessible from every other vertex. 

A vertex a from which every other vertex is accessible is called a root of G. Thus a digraph is strongly connected if and only if every vertex is a root.



Weakly-connected and strongly-connected components define unique partitions of the graph nodes.
</text>

<text>

J:
Two vertices a and b of a graph G are connected if there exists a walk
with start vertex a and end vertex b. If all pairs of vertices of G are connected,
G itself is called connected. 

For any vertex a, we consider (a) as a trivial walk
of length 0, so that any vertex is connected with itself. Thus connectedness
is an equivalence relation on the vertex set of G. 

The equivalence classes of this relation are called the connected components of G. Thus G is connected if
and only if its vertex set V is its unique connected component.

Components which contain only one vertex are also called isolated vertices. 

- A graph with n vertices and assume that each vertex of G has degree at least (n-1)/2: G must be connected.
- A graph G is connected if and only if there exists an edge e = vw with v in V1 and w in V2 whenever V = V1 U V2 is a decomposition of the vertex set of G.(that is, V1 intersect V2 = empty)

<!--  If G is not connected, the complementary graph G is connected. -->

RESULTS
- A connected graph on n vertices has at least n-1 edges.
- An acyclic graph on n vertices has at most n-1 edges.
</text>

</document>



<document>
<tag>graph-theory-distance</tag>
<title>Distance</title>

<!-- Length / strength / distance -->

<text>
The number of edges in a walk, trail, path, or cycle (i.e. <eqn>n</eqn>) defines its length given the above formal specification, albeit we can relax this definition for weighted graphs. Whereas path lengths correspond to the number of edges paths contain in binary graphs (often called hops), they can be computed using edge weights in weighted graphs. We will assume that paths composed of stronger edges span shorter lengths and, therefore, that the strength of the edge between two adjacent nodes is inversely proportional to the distance between them.
</text>


<text>
++ Distance, geodesic, eccentricity, diameter, radius

- Distance: The distance <eqn>d_G(u,v)</eqn> from a vertex <eqn>u</eqn> to a vertex <eqn>v</eqn> in a connected graph <eqn>G</eqn> is the minimum length of the paths that connect <eqn>u</eqn> and <eqn>v</eqn> in <eqn>G</eqn>.
</text>


<text>
If a and b are two vertices in the same connected component of a graph G, there has to exist a path of shortest length (say d) between a and b. (Why?)
Then a and b are said to have distance d = d(a, b) ++ Junig. Chapter 3
</text>

<text>
- Geodesic: A path of length  <eqn>d_G(u,v)</eqn> from a vertex <eqn>u</eqn> to a vertex <eqn>v</eqn> in a connected graph <eqn>G</eqn> is called a geodesic.
</text>

<text>
L: Path length is the shortest path between two nodes, and average path length is the average over all shortest paths.
= The average path length of G is equal to the average over all direct paths. This metric is also known as the characteristic path length of G.
</text>

<text>
The eccentricity of vertex v in a graph is the shortest-path distance to the farthest vertex from v. 
= the longest path from a node u to all other nodes of a connected graph

The radius of a graph is the smallest eccentricity among the vertices of G.

The diameter of a graph is the greatest eccentricity among the vertices of G.
= The longest path between any two nodes in a graph G is called the diameter of G,
</text>

<text>
For every unweighted, undirected, connected graph, the following lower and upper bounds can be defined for its diameter:
</text>

<equation>
radius(G) \leq diameter(G) \leq 2 radius(G)
</equation>

<text>
L: Diameter is amaximum value, while average path length is an average value. Thus, average path length is never greater than the diameter of the entire graph. However, it can be smaller than the radius... ?
</text>

<text>
Every vertex whose eccentricity is the radius of the graph is called a central vertex, i.e. a node with minimum eccentricity. The center of the graph is the subgraph induced by the set of vertices whose eccentricity is the radius. 
</text>

<text>
Every vertex whose eccentricity is the diameter of the graph is called a peripheral vertex, i.e. a node with the largest eccentricity. The periphery of the graph is the subgraph induced by the set of vertices whose eccentricity is the diameter of the graph. 
</text>

<text>
Two vertices whose distance between them is the diameter of the graph are said to be antipodal vertices.
</text>

<text>
The girth of a graph containing cycles is the length of a shortest cycle.
</text>

<text>
An edge linking two nodes indicates that they can communicate directly, whereas longer paths are likely to have a lower effect on the network behavior.
</text>


<text>
The pairwise distance of the shortest path linking the nodes in a network is represented in its distance matrix. Its global maximum is the network diameter. The distance matrix describes the communication pattern within the network.
</text>

</document>



<!-- Independent paths and cut sets -->

<document>
<tag>graph-theory-independent-paths</tag>
<title>Independent paths and cut sets</title>

<text>
++ Nonseparable graphs: cut-vertices (nodes) and blocks/branches 
=> vertex-cuts (vertex-connectivity), bridges (edges) 
=> edge-cuts (edge-connectivity)
</text>



<!-- Cut nodes -->

<text>
A cut vertex, cut node, cut point, or articulation point of a graph G is a vertex v such that G \ v
has more connected components than G, i.e. <eqn>k(G\v) &gt; k(G)</eqn>, where <eqn>k(G)</eqn> indicates the number of connected components of <eqn>G</eqn>.
</text>

<text>
The following properties can be proved for cut points:
</text>

<list>

<item>
Every nontrivial connected graph contains at least two nodes that are not cut-nodes (which correspond to the extremes of the longest path within the graph).
</item>

<item>
A vertex <eqn>v</eqn> is a cut-node if and only if there are two vertices <eqn>u</eqn> and <eqn>w</eqn> distinct from <eqn>v</eqn> such that <eqn>v</eqn> lies in every path between them.
</item>

</list>


<!-- Bridges -->

<text>
The removal of cut points results in a disconnected graph. There are also edges that have this property:
An edge e of a connected graph G is called a bridge if G \ e is not connected. In particular, when e is a bridge, <eqn>k(G\v) = k(G) + 1</eqn>.
</text>

<text>
An edge is a bridge of G if and only if it lies on no cycle in G.
</text>


<figure>
  <tag>fig-connectivity</tag>
  <image scale="25" file="image/graphs/bowtie"/>
  <title>The bowtie graph.</title>
</figure>

<text>
For example, let us consider the bowtie graph in Figure <ref>fig-connectivity</ref>. In this graph, both <eqn>c</eqn> and <eqn>d</eqn> are cut points (a.k.a articulation points), whereas only the <eqn>cd</eqn> edge is a bridge.
</text>

<text>
J: Which connected multigraphs can be oriented in such a way that the resulting graph is strongly connected? Such multigraphs
are called orientable. Thus we ask which connected systems of streets can be
made into a system of one-way streets such that people can still move from
each point to every other point. The answer is given by the following theorem
[Rob39].
Theorem 1.6.2 (Robbins' theorem). A connected multigraph is orientable
if and only if it does not contain any bridge.

+ G does not contain a bridge if and only if each edge of G is contained in at least one cycle.
</text>


<!-- Separable graphs -->


<text>
A connected graph containing no cut-nodes is a nonseparable graph, whereas a connected graph containing cut points is said to be separable.
</text>

<text>
It can be proved that, in any nonseparable graph with 3 nodes or more, every two vertices lie on a common cycle. Therefore, there are two internally disjoint paths between every two distinct nodes in nonseparable graphs, where internally disjoint means that they have only their end vertices in common (a.k.a. vertex-disjoint paths).
</text>

<!-- Blocks -->

<text>
The maximal induced subgraphs of a graph G which are not separable are called the blocks or biconnected components of G.
</text>

<text>
Every two distinct blocks of a given connected graph have at most one vertex in common. When they have one, this vertex is a cut point.
</text>

<text>
It can also be proved that the center of every connected graph lies in a single block of the graph.
</text>

<text>
J: Let G be a graph and s and t two vertices of G. Then a set of paths in G with start vertex s and end vertex t is called edge disjoint if no two of these paths share an edge, and vertex disjoint if no two of the paths have a vertex other than s and t in common.
</text>



<!-- Separators -->

<document>
<tag>graph-theory-separators</tag>
<title>Vertex separators and edge separators</title>

<text>
A subset A of E is called an edge separator for s and t if each path from s to t contains some edge from A. 

Similarly, a subset X of V \ {s, t} is called a vertex separator for s and t if each path from s to t meets X in some vertex.
</text>


<text>
J: The existence of disjoint paths plays an important role for questions of network
reliability: if there are k vertex disjoint paths from s to t, the connection
between s and t can still be maintained even if k-1 vertices fail, and similarly
for edges.

J: measuring the strength of connectivity of a connected
graph by the number of vertex disjoint paths (or edge disjoint paths) between
any two given vertices
</text>


</document>


<!-- k-connectivity: k-connected &amp; k-edge-connected graphs -->

<document>
<tag>graph-theory-k-connectivity</tag>
<title>Vertex connectivity and edge connectivity</title>


<!-- Vertex connectivity -->

<text>
A vertex-cut of a connected graph G is a subset S of the vertices V(G) such that G\S is disconnected.
A vertex-cut of minimum cardinality is called a minimum vertex-cut and this cardinality is known as the vertex connectivity of the graph, denoted by \kappa(G).
</text>

<text>
\kappa(G): the connectivity of a graph

min {|T| : T \subset V and G \ T is not connected} .

G is called k-connected if \kappa(G) \geq k.
</text>

<text>
for any two vertices s and t of a graph G, we denote by \kappa(s, t) the maximal
number of vertex disjoint paths from s to t in G. 


A graph G is k-connected if and only if \kappa(s, t) \geq k for any two vertices s and t of G.
</text>


<text>
A k-connected graph on n vertices contains at least <eqn>\lceil kn/2 \rceil</eqn> edges.
</text>

<text>
A connected graph with at least three vertices either contains a cut point or is 2-connected.
</text>

<text>
The maximal induced subgraphs of a graph G which are k-connected are called the k-connected components of G. The idea of k-connected components generalizes the previous concept of block or biconnected component, where <eqn>k=2</eqn>.
</text>

<!-- Edge connectivity -->

<text>
Analogously, an edge-cut of a connected graph G is a subset X of the edges E(G) such that G\X is disconnected.
An edge-cut of minimum cardinality is called a minimum edge-cut and this cardinality is known as the edge connectivity of the graph, denoted by \lambda(G).
</text>

<text>
\lambda(u, v) = the minimal cardinality of an edge separator for u and v.
</text>

<text>
The edge connectivity \lambda(G) is defined as lambda(G) = min{ \lambda(u, v) : u, v \in V }.

G is called m-fold edge connected if \lambda(G) \geq m
</text>

<text>
The following equation defines the relationship among (vertex) connectivity, edge connectivity, and maximum degree for any connected graph:
</text>

<equation>
\kappa(G) \leq \lambda(G) \leq \delta(G)
</equation>

<text>
PROOF: 

- Removing all edges incident with v obviously yields a disconnected graph, so that \lambda(G) \leq \delta(G).

- If \lambda(G) = 1, G contains a bridge e = uv. Then G cannot be 2-connected, because removing u from G
yields either a K1 or a disconnected graph. If \lambda(G) = k \geq 2, removing k - 1
edges e2, . . . , ek of an edge separator from G results in a graph H containing a
bridge e1 = uv. Therefore, if we remove from G one of the end vertices of each
of the ei distinct from u and v (for i = 2, . . . , k), we get either a disconnected
graph or a graph where e1 is a bridge (so that removing u makes the graph
disconnected). In either case, \kappa(G) \leq k = \lambda(G).
</text>

<!-- Connectivity theorems -->

<text>
By definition, a graph is connected if every two vertices are connected by at least one path. This fact can be generalized by Menger's and Whitney's theorems:
</text>

<list>

<item>Menger’s theorem (1927), edge version: Let G be a graph or digraph, and let s and t be two vertices of G. Then the maximal number of edge disjoint paths from s to t is equal to the minimum cardinality of an edge separator for s and t.</item>

<item>Menger’s theorem (1927), vertex version: Let G be a graph or digraph, and let s and t be any two non-adjacent vertices of G. Then the maximal number of vertex disjoint paths from s to t is equal to the minimum cardinality of a vertex separator for s and t.</item>

</list>

<text>
By Menger's theorem, \kappa(s, t) equals the minimal cardinality of a vertex separator for s and t whenever s and t are non-adjacent.
</text>

<text>
With the aid of Menger's theorem, k-connected graphs can be characterized as follows:
</text>

<list>

<item>Whitney's theorem (1932), vertex version: A graph G is k-connected if and only if any two vertices of G are connected by at least k vertex disjoint paths.</item>

<item>Whitney's theorem (1932), edge version: A graph G is k-edge-connected if and only if any two vertices of G are connected by at least k edge disjoint paths.</item>

</list>

<text>
This formal result completes our study of graph connectivity, by completing Menger's theorem, which was only applicable to non-adjacent vertices s and t.
</text>

</document>

</document>

</document>





<!-- Classes -->

<document>
<tag>graph-theory-classes</tag>
<title>Interesting classes of graphs</title>

<text>
Some kinds of graphs appear so often in practice that it is worthwhile to examine them in some detail.
</text>

<document>
<tag>graph-theory-regular</tag>
<title>Regular graphs</title>

<text>
When all the nodes in a graph have the same degree (say r), the graph is said to be a regular graph,
more precisely an r-regular graph. A regular graph is said to be regular of degree r when its nodes have the degree r.
</text>

<text>
The following theorem establishes the existence of regular graphs for given values of r and n: For integer r and n, there is an r-regular graph of n nodes if and only if <eqn>0 \leq r \leq n-1</eqn> and r and n are not both odd. The last condition is just a consequence of the fact that every graph must have an even number of nodes with odd degrees.
</text>

<text>
At the opposite extreme of the spectrum of regularity, an graph would be irregular if <eqn>deg(u) \neq deg(v)</eqn> for every two vertices of the graph. Such a graph, however, cannot exist, given that an irregular graph with n nodes would have a degree sequence given by <eqn>deg(v_i)=i-1</eqn>. This would imply that one node in the graph would be isolated, i.e. <eqn>deg(v_1)=0</eqn>, which is a contradiction with the fact that <eqn>deg(v_n)=n-1</eqn>, since <eqn>v_1</eqn> should also be adjacent to <eqn>v_n</eqn>.
</text>

<document>
<title>Complete graphs</title>

<text>
In a complete graph, every two distinct edges are adjacent, i.e. the size of a complete graph of order <eqn>n</eqn> is <eqn>n(n-1)/2</eqn>. The complete graph of order <eqn>n</eqn> is denoted by <eqn>K_n</eqn>. 

The complete graph Kn has n vertices (that is, |V | = n) and all two-element subsets of V as edges. 

The graph <eqn>K_n</eqn> is <eqn>(n-1)</eqn>-regular and its size is <eqn>n(n-1)/2</eqn>. Its (vertex) connectivity and edge connectivity are maximum: <eqn>\kappa(K_n) = \lambda(K_n) = n-1</eqn>.
</text>

<figure>
  <tag>fig-k5</tag>
  <image scale="25" file="image/graphs/k5"/>
  <title>The complete graph <eqn>K_5</eqn>.</title>
</figure>


<text>
++ tournament (orientation of a complete graph)

J: "Replacing each edge of the form (a, b) by an undirected edge {a, b}, we obtain the underlying multigraph |G|. Replacing parallel
edges in |G| by a single edge, we get the underlying graph (G). Conversely, let G = (V,E) be a multigraph. Any directed multigraph H with |H| = G is
called an orientation of G. Replacing each edge ab in E by two arcs (a, b) and (b, a), we get the associated directed multigraph
\overrightarrow{G}; we also call \overrightarrow{G} G the complete orientation of G. The complete orientation of Kn is called the complete
digraph on n vertices."
</text>


</document>


<document>
<title>Cubic graphs</title>

A cubic graph is a graph in which all vertices have degree three, i.e. a 3-regular graph. Cubic graphs are also called trivalent graphs.

Their (vertex) connectivity and edge connectivity always coincide, i.e. <eqn>\kappa(K_n) = \lambda(K_n)</eqn>, and they can be either 1 or 2.

There are many well-known individual cubic graphs, including the complete graph <eqn>K_4</eqn>, the utility graph (<eqn>K_{3,3}</eqn>), the Petersen graph, the Heawood graph, the Möbius-Kantor graph, the Pappus graph, the Desargues graph, the Nauru graph, the Coxeter graph, the Tutte-Coxeter graph (a.k.a. Tutte eight-cage), the Dyck graph, the Foster graph, or the Biggs-Smith graph.

For instance, the Petersen graph is an undirected small regular graph, named after the Danish mathematician Julius Petersen, who initiated the study of regular graphs in 1891. The Petersen graph, which includes 10 vertices and 15 edges, is often employed as an useful example or counterexample for many proofs in graph theory.

<figure>
  <tag>fig-petersen</tag>
  <image scale="30" file="image/graphs/petersen"/>
  <title>The Petersen graph, a typical example of cubic graph.</title>
</figure>

</document>

<!--
<document>
<title>Triangular graphs</title>

J: he triangular graph Tn has as vertices the two-element subsets of a set with n elements. Two of these vertices are adjacent if and only if their intersection is not empty. Obviously, Tn is a (2n-4)-regular graph. 

Tn has even stronger regularity properties: the number of vertices adjacent to two given vertices x, y depends only on whether x and y
themselves are adjacent or not. Such a graph is called a strongly regular graph, abbreviated by SRG.

SRG: Tn has parameters a = 2n - 4, c = n - 2 and d = 4, where a is the degree of any vertex, c is the number of vertices adjacent to both x and y if x and y are adjacent, and d is the number of vertices adjacent to x and y if x and y are not adjacent. Let G be an SRG with parameters a, c, and d having n vertices. Its complementary graph \overline{G} is also an SRG. 

Theorem: a(a - c - 1) = (n - a - 1)d.

</document>
-->


</document>



<document>
<title>Grids</title>

<figure>
  <tag>fig-grid</tag>
  <image scale="30" file="image/graphs/grid"/>
  <title>A simple 5x4 2D grid.</title>
</figure>

</document>



<document>
<tag>graph-theory-bipartite</tag>
<title>Bipartite graphs</title>

<text>
A graph G is bipartite if its vertex set V(G) can be partitioned into two disjoint sets L and R (called partite sets) so that every edge in G joins a node in L with a node in R.
</text>

<text>
If a bipartite graph is regular, then |L|=|R| and its size will be r|L|=r|R| assuming that it is r-regular. 
</text>

<text>
A bipartite graph is said to be a complete bipartite graph if it is bipartite and uv is an edge of G if and only if u \in L and w \in R.

The complete bipartite graph Ks,t has as vertex set the disjoint union of a set V1 with s elements and a set V2 with t elements; edges are all the
sets {a, b} with a in V1 and b in V2. 

Since the size of the complete bipartite graph <eqn>K_{\lfloor n/2 \rfloor, \lceil n/2 \rceil}</eqn> is <eqn>\lfloor n/2 \rfloor \cdot \lceil n/2 \rceil = \lfloor n^2/4 \rfloor</eqn>, no bipartite graph can have a larger size than <eqn>\lfloor n^2/4 \rfloor</eqn>.

From the previous result, we can conclude that every graph with more than two nodes and size larger than <eqn>\lfloor n^2/4 \rfloor</eqn> necessarily contains a triangle.

Obviously, the graph Ks,t is regular only if s = t (in that case, it is s-regular). 
</text>

<figure>
  <tag>fig-k33</tag>
  <image scale="30" file="image/graphs/k33"/>
  <image scale="20" file="image/graphs/k33pos"/>
  <title>Two different renderings of the complete bipartite graph <eqn>K_{3,3}</eqn>.</title>
</figure>


<text>
- The utility graph, also known as the Thomsen graph or K_{3,3}: cubic (3-regular), nonplanar graph.

- The complete bipartite graph K_{1,t} is called a star, a special kind of tree.
</text>


</document>


<document>
<tag>graph-theory-trees</tag>
<title>Trees</title>

<text>
Trees are connected acyclic graphs.

- connected graph with n-1 edges and n nodes.
- every edge is a bridge, since there are no cycles.
- every two nodes are connected by a unique path.

DEFINITION

Let G be a graph with n vertices. Then any two of the following conditions imply the third:
(a) G is connected.
(b) G is acyclic.
(c) G has n - 1 edges.
graph T for which the conditions of Theorem 1.2.8 hold is called a tree.
A vertex of T with degree 1 is called a leaf.  ++ Juningkel Chapter 4.
</text>

<text>
Let (d1, . . . , dn) be a sequence of positive integers. Show
that there is a tree on n vertices having degrees d1, . . . , dn if and only if
d1 + . . . + dn = 2(n - 1),
</text>



<text>
A forest is a graph without cycles, i.e. a graph whose connected components are trees. Obviously, a forest of n nodes with k connected components has n-k links.
</text>


<text>
Trees are recursive structures, since cutting any edge leaves two smaller trees.
</text>


<text>
++ Rooted vs. free:

- Rooted trees define a hierarchical order, emanating from a single source node
identified as the root.
- Free trees do not encode any structure beyond their connection topology.
</text>

<text>
J: Directed trees can never be strongly connected; here, of course, a digraph
G is called a tree if its underlying graph |G| is a tree. If G has a root r, we call G a directed tree, an arborescence or a branching with root r.

Clearly, given any vertex r, an undirected tree has exactly one orientation as a directed tree with root r.
</text>

<text>
There are several well-known classes of trees:
</text>

<list>
<item>Paths <eqn>P_n</eqn>, which are the trees with the minimum number of leaves (just <eqn>2</eqn> of them).</item>
<item>Stars <eqn>K_{1,n-1}</eqn>, which are the trees with the maximum possible number of leaves: <eqn>n-1</eqn> leaves.</item>
<item>Double stars, i.e. a tree containing exactly two non-leaves, which must be adjacent.</item>
<item>Caterpillars, when the removal of the tree leaves produces a path (the spine of the caterpillar). Paths, stars, and double stars are also caterpillars.</item>
</list>

<figure>
  <tag>fig-trees</tag>
  <image scale="20" file="image/graphs/star"/>
  <image scale="35" file="image/graphs/double-star"/>
  <image scale="50" file="image/graphs/caterpillar"/>
  <title>Well-known kinds of trees: stars, double stars, and caterpillars.</title>
</figure>


<text>
By f(n, s) we denote the number of forests G having n vertices and exactly s connected components,
for which s fixed vertices are in distinct components; in particular, the number
of trees on n vertices is f(n, 1). Cayley's theorem gives a formula for the numbers f(n, s)
</text>

<equation>
f(n, s) = sn^{n-s-1}
</equation>

<document>
<title>Prüfer codes</title>

<text>
As a corollary, we can conclude that the number of trees on <eqn>n</eqn> vertices is <eqn>n^{n-2}</eqn>, which is also the cardinality of the set of
words of length <eqn>n-2</eqn> over an alphabet with <eqn>n</eqn> elements. We can then specify a bijection between both sets: the set of trees with <eqn>n</eqn> nodes and the set of words of length <eqn>n-2</eqn> over <eqn>n</eqn> symbols. The Prüfer code is such a bijection and it allows us to represent trees as strings of <eqn>n-2</eqn> integers.
</text>


<text>
++ Prüfer codes (parents) [Prü 1918]

J: As we will need an ordering of the elements of V , we assume in what follows, without loss of generality, that V is a subset of N.
Thus let G = (V,E) be a tree. 

For n = 2 the only tree on V is mapped to the empty word; that is, we put \pi_V (G) = (). For n \geq 3 we use the smallest leaf of G to construct a tree on n-1 vertices. We write v = v(G) = min{u \in V : deg_G(u) = 1} and denote by e = e(G) the unique edge incident with v, and by w = w(G)
the other end vertex of e.

Now let G' = G \ v. Then G' has n-1 vertices, and we may assume by induction that we know the word corresponding to G'
under the Prüfer code on V' = V \ {v}. Hence we can define recursively \pi_V (G) = (w, \pi_{V'} (G'))

It remains to show that we have indeed constructed the desired bijection. We need the following lemma which allows us to determine the minimal leaf of a tree G on V from its Prüfer code: 

Let G be a tree on V . Then the leaves of G are precisely those elements of V which do not occur in \pi_V (G). In particular,
v(G) = min{u \in V : u does not occur in \pi_V (G)}.
</text>

<text>
EXAMPLES: shows some trees and their Prüfer codes for n = 6, one for each isomorphism class <cite>Jungnickel 2007</cite>,
- (1 (2 (3 (4 (5 (6)))))) = (2,3,4,5)
- (1 (2 (3 (4 (5 6))))) = (2,3,4,4)
- (1 (2 (3 (4 5 6)))) = (2,3,3,3)
- (1 (2 (3 (4)) (5 (6)) )) = (2,3,2,5)
- (1 (2 (3 4 (5 6)))) = (2,2,4,4)
- (1 (2 3 4 5 6) = (1,1,1,1)
</text>

<figure>
  <tag>fig-trees</tag>
  <image scale="80" file="image/graphs/trees"/>
  <title>Trees with six nodes.</title>
</figure>

<text>
+ The degree of a node is one more than the number of times its value appears in the Prüfer sequence
</text>

<text>
a simple way to rank and unrank labeled trees and solve any tree generation problem: Exactly n^(n-2) labeled trees on n vertices, which correspond to that many strings of length n-2 on the alphabet {1..n}.

NOTE: There are two models for generating data such as permutations: ranking/unranking (biyective function) and incremental change methods (iterators). Ranking/unranking methods make it trivial to generate random data (just generate a random number and rank), whereas enumeration by incremental change methods makes it tricky to generate random data (e.g. needed to solve some hard problems using randomized algorithms)

e.g. permutations [Knuth05a]

INCORRECT (does not generate permutations uniformly!) 

for i=1..n 
  a[i] = i

for j=1..n-1
  swap( a[i], a[random(1,n)]

CORRECT VERSION

for i=1..n 
  a[i] = i

for j=1..n-1
  swap( a[i], a[random(i,n)]

</text>

</document>

<note>
<title>Spanning trees</title>

<text>
Cayley's tree formula, which states that there are <eqn>n^(n-2)</eqn> labeled trees of <eqn>n</eqn> nodes, can be interpreted from a different point of view: there can be <eqn>n^(n-2)</eqn> different spanning trees of the labeled complete graph <eqn>K_n</eqn>. Kirchhoff's matrix-tree theorem gives us the number of non-identical spanning trees of labeled graphs in general.
</text>

<!-- equal to the value of any cofactor of the degree matrix of G minus the adjacency matrix of G. -->
</note>

</document>



<document>
<tag>graph-theory-dag</tag>
<title>Directed acyclic graphs</title>

<text>
++ Directed acyclic graphs (DAGs), a.k.a. partial orders or posets, arise in many applications, e.g. scheduling and planning
</text>

<text>
Let <eqn>(M,\preceq)</eqn> be a partially ordered set, a poset for short. This is a set M together with a reflexive, antisymmetric and transitive relation <eqn>\preceq</eqn>. This set corresponds to a directed graph G having vertex set M and the pairs (x,y) with x \preceq y as edges. Because of transitivity, G is acyclic.
</text>


<text>
+ Topological sorting orders the vertices of a DAG respecting the precedence constraints imposed by the arcs in the DAG.

J: common problem is to check whether a given directed graph is acyclic
and, if this is the case, to find a topological sorting of its vertices. That is, we
require an enumeration of the vertices of G (labelling them with the numbers
1, . . . , n, say) such that i &lt; j holds for each edge ij. Such a sorting exists for every directed acyclic graph.
</text>

<text>
+ Let G be a directed acyclic graph. Then G contains at least one vertex with din(v) = 0.

JJ: we may choose a vertex v with din(v) = 0. Consider the directed graph H = G\ v. Obviously, H is acyclic as well and thus can be sorted topologically, using induction on the number of vertices, say by labelling the vertices as v2, . . . , vn. Then (v, v2, . . . , vn) is the desired topological sorting of G.
</text>

<text>
J: Each partially ordered set may be embedded into a linearly
ordered set.
Proof. Let (v1, . . . , vn) be a topological sorting of the corresponding directed
acyclic graph. Then vi . vj always implies i &lt; j, so that v1 . . . . . vn is a
complete linear ordering
</text>

</document>



<document>
<title>Planar graphs</title>


<text>
J: Let E be a set of line segments in three-dimensional Euclidean space and V the set of end points of the line segments in E. Identifying each line segment with the two-element set of its end points, we can consider (V,E) as a graph. Such a graph is called geometric if any two line segments in E are disjoint or have one of their end points in common.
Lemma 1.5.1. Every graph is isomorphic to a geometric graph.
</text>

<text>
J: We call a geometric graph plane if its line segments all lie
in one plane (often allows not only line segments, but
curves as well, e.g. they are necessary to represent multigraphs). 
Any graph isomorphic to a plane graph is called planar 
</text>

<text>
J: Thus,
the planar graphs are exactly those graphs which can be drawn in the plane
without additional points of intersection between the edges

Planar graphs, i.e. those that can be drawn on a plane without link crossings, are common in many applications. 
</text>

<text>
J: If we omit the line segments of G from the plane surface on which G is drawn, the remainder splits into a number
of connected open regions; the closure of such a region is called a face. 

Euler's formula). Let G be a connected planar graph with
n vertices, m edges and f faces. Then n - m + f = 2.

e.g. Euler's formula was applied to the vertices, edges and faces
of a convex polyhedron, which are planar; it is used, for example, to determine the five regular
polyhedra (or Platonic solids, namely the tetrahedron, octahedron, cube,
icosahedron and dodecahedron);
</text>

<text>
A bound on the number of edges of planar graphs:
Planar graphs are always sparse, since they have at most <eqn>3n-6</eqn> links. 
</text>

<text>
Trees, for instance, are always planar graphs.
</text>

<note>
<title>Graph homeomorphism</title>

<text>
J: A subdivision of a graph G is a graph H which can be derived from G by
applying the following operation any number of times: replace an edge e = ab
by a path (a, x1, . . . , xk, b), where x1, . . . , xk are an arbitrary number of new
vertices; that is, vertices which were not in a previous subdivision. For convenience,
G is also considered to be a subdivision of itself. 
</text>

<text>
J: Two graphs H and H' are called homeomorphic 
if they are isomorphic to subdivisions of the same
graph G.
</text>

</note>

<text>
J: the famous characterization of planar graphs:

Kuratowski's theorem: A graph G is planar if and only if it does not contain a subgraph which is homeomorphic to K5 or K3,3.

W: Two important characterizations of planar graphs, Kuratowski's theorem that the planar graphs are exactly the graphs that contain neither K3,3 nor the complete graph K5 as a subdivision, and Wagner's theorem that the planar graphs are exactly the graphs that contain neither K3,3 nor K5 as a minor, encompass this result.

J: another interesting characterization of planarity. If we identify
two adjacent vertices u and v in a graph G, we get an elementary contraction
of G; more precisely, we omit u and v and replace them by a new vertex w
which is adjacent to all vertices which were adjacent to u or v before
the resulting graph is usually denoted by G/e, where e = uv.
A graph G is called contractible to a graph H if
H arises from G by a sequence of elementary contractions. 

Wagner's theorem: A graph G is planar if and only if it does not contain a subgraph which is contractible to K5 or K3,3.
</text>

<text>
Example: The Petersen graph is not planar,
</text>

</document>


</document>


<!-- Graphs as matrices -->

<document>
<tag>graph-theory-matrix</tag>
<title>Graphs as matrices</title>

<text>
Up to this point, we have described graphs by means of sets of nodes and ordered pairs and we have illustrated them with the help of simple line diagrams. However, a matrix representation of graphs is also possible, as we will see in this section.
</text>

<text>
Whereas set theory might be especially suitable for providinf formal definitions and proving theorems, for data analysis a matrix representation is
more useful.
</text>

<document>
<tag>graph-theory-matrix-adjacency</tag>
<title>The adjacency matrix</title>

<text>
Let G be a graph with n nodes. The adjacency matrix of the graph G is the <eqn>n \times n</eqn> binary matrix <eqn>A(G) = [a_{ij}]</eqn> where
</text>

<equation>
a_{ij} = 
\left \{
\begin{matrix}
 1 &amp; if &amp; v_iv_j \in E(G)\\ 
 0 &amp; if &amp; v_iv_j \notin E(G)
\end{matrix}
\right.
</equation>

<text>
For example, the adjacency matrix of the complete graph <eqn>K_5</eqn> is
</text>

<equation>
A(K_5) =
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 
\end{bmatrix}
</equation>

<text>
Whereas the adjacency matrix of the complete bipartite graph <eqn>K_{3,3}</eqn> is
</text>

<equation>
A(K_{3,3}) =
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
</equation>

<text>
Several observations can be made about such adjacency matrices:
</text>

<list>

<item>
The adjacency matrix <eqn>A</eqn> is a symmetric matrix for undirected graphs, since <eqn>a_{ij} = a_{ji}</eqn> for such graphs, but it certainly might nt be symmetric for directed graphs.
</item>

<item>
All elements along the main diagonal of <eqn>A</eqn> are 0 if we do not allow loops (i.e. a vertex cannot be adjacent to itself).
</item>

<item>
We can obtain the degree of the i-th node of an undirected graph just by adding the entries in row i (or, alternatively, in column i).
</item>

<item>
Similarly, the sum of the entries in row i gives us the out-degree of the ith node in a directed graph, while the sum of the entries in column i gives us its in-degree.
</item>

<item>
When <eqn>a_{ij} = 1</eqn>, the graph contains the edge <eqn>v_iv_j</eqn> and there is a path from <eqn>v_i</eqn> to <eqn>v_j</eqn> of length 1.
</item>

</list>

<text>
This last observation can be exploited to determine whether the graph contains a walk from <eqn>v_i</eqn> to <eqn>v_j</eqn> of length <eqn>k</eqn> for any arbitrary positive integer <eqn>k</eqn>. In fact, the number of different walks of length <eqn>k</eqn> from <eqn>v_i</eqn> to <eqn>v_j</eqn> is given by the <eqn>(i,j)</eqn> entry in the matrix <eqn>A^k</eqn>.
</text>

<text>
Let <eqn>a_{ij}^{(k)}</eqn> denote the <eqn>(i,j)</eqn> entry in the matrix <eqn>A^k</eqn>. We can obtain the following data just by multiplying the adjacency matrix by itself:
</text>

<list>

<item>
The degree of a node: <eqn>d_i = deg(v_i) = a_{ii}^{(2)}</eqn>.
</item>


<text>
++ Counting the number of paths of length k by matrix multiplication: A^k (includes non-simple paths), e.g. divide-and-conquer algorithm @ Skiena 425 [Karatsuba KO63], fast multiplication algorithms @ Skiena 403 [Strassen 69][Coppersmith 90][CKSU05]
</text>

<item>
The number of triangles in G than contain a given node: <eqn>triangles(v_i) = a_{ii}^{(3)} / 2</eqn>.
</item>

</list>

<figure>
  <tag>fig-bowtie</tag>
  <image scale="25" file="image/graphs/bowtie"/>
  <title>The bowtie graph.</title>
</figure>

<text>
For instance, consider the bowtie graph in Figure <ref>fig-bowtie</ref> and the powers of its adjacency matrix:
</text>

<equation>
A(G_{bowtie}) =
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 
\end{bmatrix}
</equation>

<equation>
A^2(G_{bowtie}) =
\begin{bmatrix}
2 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 2 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 3 &amp; 0 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 3 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 2
\end{bmatrix}
</equation>

<equation>
A^3(G_{bowtie}) =
\begin{bmatrix}
2 &amp; 3 &amp; 4 &amp; 1 &amp; 1 &amp; 1 \\
3 &amp; 2 &amp; 4 &amp; 1 &amp; 1 &amp; 1 \\
4 &amp; 4 &amp; 2 &amp; 5 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 5 &amp; 2 &amp; 4 &amp; 4 \\
1 &amp; 1 &amp; 1 &amp; 4 &amp; 2 &amp; 3 \\
1 &amp; 1 &amp; 1 &amp; 4 &amp; 3 &amp; 2
\end{bmatrix}
</equation>

<text>
Nodes <eqn>c</eqn> and <eqn>d</eqn> have degree 3, while the remaining nodes have degree 2, as can be seen in <eqn>A^2</eqn>. Observing <eqn>A^3</eqn>, we can conclude that every node in the graph is part of a single triangle and also that all the nodes in the graph are connected by paths whose length is at most 3, since all entries in <eqn>A^3</eqn> are distinct from zero, which indicates that walks of length 3 exist for every pair of nodes in the graph.
</text>

<note>
<text>
Note: The adjacency matrix is also known as the <term>sociomatrix</term> in social network analysis.
</text>
</note>

<text>
The spectral decomposition of the adjacency matrix also provides valuable insight into the nature of a graph. The <term>spectral radius</term> <eqn>\rho(G)</eqn> is computed from the adjacency matrix as its the largest non-trivial (i.e. non-zero) eigenvalue. The largest eigenvalue of the adjacency matrix, often denoted by <eqn>\kappa_1</eqn>, is never below the average degree of the network <eqn>\langle d \rangle = 2m / n</eqn>, nor below the square root of the largest degree <eqn>\Delta</eqn>. Spectral eigenvalues are also called <term>characteristic eigenvalues</term> because they characterize the topology of a graph in succinct terms (in fact, they are completely determined by the graph degree sequence) and they can be useful when analyzing the dynamic behavior of networks (e.g. the spectral radius can determine the persistence of an infection).
</text>

</document>




<document>
<tag>graph-theory-matrix-incidence</tag>
<title>The incidence matrix</title>

<text>
Alternatively, we can describe a graph by means of an edge incidence matrix. The edge incidence matrix of a network with <eqn>n</eqn> nodes and <eqn>m</eqn> links is an <eqn>m \times n</eqn> matrix <eqn>B</eqn> with elements
</text>

<equation>
b_{ij} = 
\left \{
\begin{matrix}
 +1 &amp; \text{if the head of edge} i \text{is attached to vertex} j\\ 
 -1 &amp; \text{if the tail of edge} i \text{is attached to vertex} j\\
 0  &amp; \text{otherwise}
\end{matrix}
\right.
</equation>

<text>
The sum <eqn>\sum_k b_{ki}b_{kj}</eqn> will be -1 if there is an edge from vertex i to vertex j and zero otherwise.
When i=j, this sum becomes <eqn>\sum_k b_{ki}^2</eqn> and returns the degree of the ith vertex <eqn>d_i</eqn>.
</text>

<text>
The edge incidence matrix for the bowtie graph is
</text>

<equation>
B(G_{bowtie}) = 
\begin{bmatrix}
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
\end{bmatrix}
</equation>

</document>



<document>
<tag>graph-theory-matrix-connection</tag>
<title>The connection matrix</title>

<text>
In multigraphs, each entry in the connection matrix represents the number of links connecting node i to node j. Formally, <eqn>C(G) = [c_{ij}]</eqn>, where
</text>

<equation>
c_{ij} = 
\left \{
\begin{matrix}
 k_{ij} &amp; if &amp; v_iv_j \in E(G)\\ 
 0 &amp; if &amp; v_iv_j \notin E(G)
\end{matrix}
\right.
</equation>

<text>
and <eqn>k_{ij}</eqn> is the number of links connecting <eqn>v_{i}</eqn> to <eqn>v_{j}</eqn>.
</text>

<text>
For simple graphs, it is clear that <eqn>C(G) = A(G)</eqn>. Hoewever, the connection matrix and the adjacency matrix are different for multigraphs and pseudographs, since parallel edges and loops are not reflected on adjacency matrices. An adjacency matrix contains a 1 in its (i,j) entry whenever a link connect node i to node j, but parallel edges (i.e. duplicate links connecting the same pair of  nodes) are ignored in the adjacency matrix, not so in the connection matrix.
</text>

</document>



<document>
<tag>graph-theory-matrix-degree</tag>
<title>The degree matrix</title>

<text>
Let G be a graph with n nodes. The degree matrix of the graph G is the <eqn>n \times n</eqn> matrix <eqn>D(G) = [d_{ij}]</eqn> where
</text>

<equation>
d_{ij} = 
\left \{
\begin{matrix}
 d_i &amp; if &amp; i = j \\ 
 0   &amp; if &amp; i \neq j
\end{matrix}
\right.
</equation>

<text>
where <eqn>d_i = deg(v_i)</eqn>.
</text>


<text>
The degree matrix of the bowtie network is, then,
</text>

<equation>
D(G_{bowtie}) = 
\begin{bmatrix}
 2 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  2 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp;  3 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp;  0 &amp;  3 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp;  0 &amp;  0 &amp;  2 &amp;  0 \\
 0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp;  2 
\end{bmatrix}
</equation>


</document>



<!--
<document>
<tag>graph-theory-matrix-distance</tag>
<title>The path/distance matrix</title>

<text>
a.k.a. path matrix (entries equal to the path length separating nodes, or zero, if no path exists)
</text>

L: Path matrix P(G) stores the number of hops along the direct path between all node
pairs in a graph; that is, P(G) enumerates the lengths of shortest paths among all
node pairs. If the graph is undirected, then P(G) is symmetric. Also, as with the adjacency
matrix, if no link exists between a node pair, the corresponding element in
P(G) is zero. The diagonal elements of P(G) are zero because we eliminate loops
from consideration, as well as duplicate links.

L: Let D be the size of the longest path—the diameter of G. 
Then, P(G) = min_{k=1..D} {k A^k(G)}
Powers of adjacency matrix A also contain cycles of length k along the diagonal of Ak. Here, we ignore cycles, so the diagonal elements are set to zero after each multiplication.

</document>
-->

<document>
<tag>graph-theory-laplacian</tag>
<title>The Laplacian matrix</title>

<text>
The graph <term>Laplacian</term> is formed by inserting the degree of the nodes into the diagonal of the adjacency matrix, i.e. it combines the adjacency information in the adjacency matrix with node degree information from the degree matrix. The de-facto standard definition of the graph Laplacian has become
</text>

<equation>
L(G) = D(G) - A(G)
</equation>

<text>
with positive values along the diagonal representing node degrees and non-positive values elsewhere; i.e. -1 at its (i,j)-entry if there is an edge connecting <eqn>v_i</eqn> and <eqn>v_j</eqn>. Alternatively, the graph Laplacian can be written as:
</text>

<equation>
l_{ij} = \delta_{ij}d_{i} - a_{ij}
</equation>

<text>
where <eqn>\delta_{ij}</eqn> is the Kronecker delta, which is 1 if <eqn>i=j</eqn> and 0 otherwise.
</text>

<text>
The Laplacian matrix is designed so that the sum of its row elements is always zero. When the matrix is symmetric, as in undirected graphs, the sum of its columns is also zero. This fact is important, for example, when using the graph Laplacian to study the stability of networks.
</text>


<text>
The Laplacian matrix of the previous bowtie network is, therefore,
</text>

<equation>
L(G_{bowtie}) = 
\begin{bmatrix}
 2 &amp; -1 &amp; -1 &amp;  0 &amp;  0 &amp;  0 \\
-1 &amp;  2 &amp; -1 &amp;  0 &amp;  0 &amp;  0 \\
-1 &amp; -1 &amp;  3 &amp; -1 &amp;  0 &amp;  0 \\
 0 &amp;  0 &amp; -1 &amp;  3 &amp; -1 &amp; -1 \\
 0 &amp;  0 &amp;  0 &amp; -1 &amp;  2 &amp; -1 \\
 0 &amp;  0 &amp;  0 &amp; -1 &amp; -1 &amp;  2 
\end{bmatrix}
</equation>

<text>
The Laplacian matrix can also be expressed in terms of the edge incidence matrix:
</text>

<equation>
L = B^t B
</equation>

<text>
since <eqn>l_{ij} = \sum_k b_{ki}b_{kj}</eqn>.
</text>

<text>
The name of the Laplacian matrix comes from the Laplacian operator <eqn>\nabla^2</eqn> that appears on the diffusion equation for a gas, which is replaced by the Laplacian matrix when we model a diffusion process on a network. In this diffusion process, we assume that we have an amount <eqn>\psi_i</eqn> of some kind of commodity at each node and the commodity moves along the edges, flowing from a vertex <eqn>j</eqn> to an adjacent one <eqn>i</eqn>, at a rate given by <eqn>C(\psi_j-\psi_i)</eqn>, where <eqn>C</eqn> is the diffusion constant. Then, from the system of equations given by 
</text>

<equation>
\frac{d\psi_i}{dt} = C \sum_j a_{ij} (\psi_j-\psi_i)
</equation>

<text>
we can obtain the following equation in matrix form:
</text>

<equation>
\frac{d\psi}{dt} + C L \psi = 0
</equation>

<text>
This diffusion equation can be solved by writing the vector <eqn>\psi</eqn> as a linear combination of the eigenvectors <eqn>\vec{v_i}</eqn> of the Laplacian, i.e. <eqn>L\vec{v_i} = \lambda_i \vec{v_i}</eqn> where <eqn>\lambda_i</eqn> is the eigenvalue corresponding to the eigenvector <eqn>\vec{v_i}</eqn>, we obtain
</text>

<equation>
\psi(t) = \sum_i a_i(t) \vec{v_i}
</equation>

<equation>
a_i(t) = a_i(0) e^{-C \lambda_i t}
</equation>

<text>
Given the initial conditions of the network, specified by <eqn>a_i(0)</eqn>, we can solve for any later time. Since the Laplacian is a symmetric matrix for undirected networks, it has real eigenvalues. Moreover, all its eigenvalues are non-negative, since they can be expressed as the inner product of a real vector <eqn>B \vec{v_i}</eqn> with itself. This means that the diffusion solution contains only decaying exponentials or constants (for <eqn>\lambda_1 = 0</eqn>), so the process tends to an equilibrium and does not diverge (a reasonable solution if we take into account that the existing amounts <eqn>\psi_i</eqn> are finite from the start).
</text>

<!-- Spectral gap -->

<text>
Let us suppose that a network is divided into <eqn>c</eqn> different components. Then, if we order the vertices so that the first <eqn>n_1</eqn> correspond to the first component, the next <eqn>n_2</eqn> to the second component, and so on, the network Laplacian will be block diagonal. In fact, each block in the Laplacian will be the Laplacian of the corresponding component.
</text>

<text>
Taking into account the definition of the Laplacian as <eqn>l_{ij} = \delta_{ij}d_{i} - a_{ij}</eqn>, when we multiply the vector <eqn>\vec{1}</eqn>, made of ones, by the Laplacian, the ith element of the result will be
</text>

<equation>
\sum_j l_{ij} \times 1 = \sum_j ( \delta_{ij}d_{i} - a_{ij} ) = d_{i} - \sum_j a_{ij} = d_{i} - d_{i} = 0
</equation>

<text>
That is, the vector <eqn>\vec{1}</eqn> is an eigenvector of the Laplacian with eigenvalue 0. If we return to our disconnected network, we can easily obtain <eqn>c</eqn> eigenvectors with eigenvalue zero: the vectors with ones in the positions corresponding to vertices in a single component and zeros elsewhere. Actually, the number of zero eigenvalues is always exactly equal to the number of connected components. As a corollary, we can assert that the network is connected if and only if the second eigenvalue of the network Laplacian <eqn>\lambda_2</eqn> is non-zero. The second eigenvalue of the network Laplacian is called the <term>algebraic connectivity</term> of the network and it is also known as its <term>spectral gap</term> <eqn>\sigma(G)</eqn>.
</text>


<text>
Apart from diffusion processes, which model epidemics, the spread of contagions, rumors, ideas, and group consensus, as well as the spread of chaos throughout a graph, the graph Laplacian also appears in the study of random walks on networks, network connectivity, graph parititioning, and network stability (or the lack of it, which can often be explained by the spectral gap).
</text>

<comment>

<text>
Some authors resort to a normalized Laplacian matrix when they want all elements of L to be less than one. This normalized version is usually defined so that the resulting matrix has ones along its diagonal. Rather than using the Boolean values of the adjacency matrix, adjacency is indicated by
</text>

<equation>
l_{ij} = 
\left \{
\begin{matrix}
 \frac{-1}{\sqrt{d_i d_j}} &amp; if &amp; v_iv_j \in E(G) \\ 
 0        &amp; if &amp; v_iv_j \notin E(G) 
\end{matrix}
\right.
</equation>

<text>
The expression above is the result of defining the Laplacian as <eqn>L = I - D^{-1/2}AD^{-1/2}</eqn>, where <eqn>I</eqn> is the identity matrix, a square matrix with ones on the main diagonal and zeros elsewhere. The Laplacian sometimes is defined as <eqn>L = D^{-1}A - I</eqn>, but none of these alternative definitions yield a matrix whose rows and columns that sum to zero (a useful property when studying network synchronization). Henceforth, we will assume that <eqn>L = D - A</eqn>.
</text>

</comment>

</document>


</document>



<document>
<tag>graph-theory-notes</tag>
<title>Bibliographic notes</title>

<text>
Origin of graph theory: Euler founded the field he called <q>geometria situs</q> (geometry of position), what is now known as graph theory.
</text>

<text>
Euler 1736 @ Könisberg Bridges == Eulerian circuits and Eulerian trails.
</text>

<text>
<q>In addition to that branch of geometry which is concerned with magnitudes, and
which has always received the greatest attention, there is another branch, pre-
viously almost unknown, which Leibniz first mentioned, calling it the geometry
of position. This branch is concerned only with the determination of position
and its properties; it does not involve measurements, nor calculations made
with them. It has not yet been satisfactorily determined what kind of problems
are relevant to this geometry of position, or what methods should be used in
solving them. Hence, when a problem was recently mentioned, which seemed
geometrical but was so constructed that it did not require the measurement of
distances, nor did calculation help at all, I had no doubt that it was concerned
with the geometry of position - especially as its solution involved only position,
and no calculation was of any use...</q> translated from <q>Solution of a problem relating to the geometry of position</q> <cite>Euler 1736</cite>
</text>

<text>
[Wikipedia] In 1736 Euler solved, or rather proved unsolvable, a problem known as the seven bridges of Königsberg. The city of Königsberg, Kingdom of Prussia (now Kaliningrad, Russia) is set on the Pregel River, and included two large islands which were connected to each other and the mainland by seven bridges. The question is whether it is possible to walk with a route that crosses each bridge exactly once, and return to the starting point. Euler's solution of the Königsberg bridge problem is considered to be the first theorem of graph theory. In addition, his recognition that the key information was the number of bridges and the list of their endpoints (rather than their exact positions) presaged the development of topology <cite>Alexanderson 2006</cite>.
This stamp of the former German Democratic Republic honoring Euler displaying his formula relating the number of faces, edges and vertices of a convex polyhedron. Euler also made contributions to the understanding of planar graphs. He introduced a formula governing the relationship between the number of edges, vertices, and faces of a convex polyhedron. Given such a polyhedron, the alternating sum of vertices, edges and faces equals a constant: V-E+F=2.
</text>


<text>
++ William Rowan Hamilton's Icosian Game @ 1856: Hamiltonian circuits. 

"Hamiltonian cycles apparently first arose in Euler's study of the knight's tour problem, although they were popularized by Hamilton's “Around the World” game in 1839."
</text>

<text>
Two 19th Century examples: Kirchhoff 1847 work on electrical networks (the foundation of circuit theory in electrical engineering) and Cayley 1857 use of trees to count alkanes (chemical compounds) = enumerating chemical isomers, molecules that contain the same number of atoms bonded in different ways.
</text>

<text>
The term graph was not used in its current sense until 1878, when J.J. Sylvester used it instead of <q>linkage</q>, which was the term used to refer to graphs at that time <cite>Gross and Yellen 2003</cite>.
</text>

<text>
First two books on graph theory: <cite>Konig 1936</cite> in German (English translation: <cite>Konig 1990</cite>) and <cite>Berge 1958</cite> in French (English translation: <cite>Berge 2001</cite>).
</text>

<text>
The first major book on graph theory written in English: <cite>Ore 1962</cite>.
</text>

<text>
The only other major book on graph theory published in English before 1970: <cite>Harary 1969</cite>
</text>

<text>
A retrospective from one of the key players in the development of graph theory: <cite>Tutte 1998</cite>
</text>

<text>
++ Other textbooks: <cite>Bondy and Murty 1976</cite> 
</text>

<text>
++ Modern textbooks, e.g. <cite>Chartrand et al. 2011</cite> <cite>Jungnickel 2007</cite> <cite>Diestel 2005</cite> <cite>Gross and Yellen 2005</cite> <cite>Gross and Yellen 2003</cite> <cite>Bollobas 2002</cite>. 
</text>

<text>
[note] Pure mathematics, not always with practical applications.
</text>

<text>
++ Introductory divulgative books, e.g. <cite>Chartrand 1984</cite>
</text>


</document>

</document>
